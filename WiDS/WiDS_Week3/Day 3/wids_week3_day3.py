# -*- coding: utf-8 -*-
"""WiDS_Week3_Day3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vEPAZggX1AciM2bqHT-Bjjgv9p62I6Qk
"""

import gymnasium as gym
from gymnasium import spaces
import numpy as np

class TradingEnv(gym.Env):
  metadata = {"render_modes": []}

  def __init__(self, max_steps = 100):
    super().__init__()

    self.initial_cash = 10_000.00
    self.initial_price = 100.00
    self.max_steps = max_steps
    self.prev_portfolio_value = None
    self.k_inventory = 0.01
    self.k_risk = 0.1

    self.action_space = spaces.Discrete(3)

    self.observation_space = spaces.Box(
        low = np.array([0.0, -1.0, 0.0], dtype = np.float32),
        high = np.array([2.0, 1.0, 2.0], dtype = np.float32)
    )

    self.reset()

  def reset(self, seed = None, options = None):
    super().reset(seed = seed)

    self.price = self.initial_price
    self.inventory = 0
    self.cash = self.initial_cash
    self.timestamp = 0
    self.prev_portfolio_value = self._portfolio_value()

    obs = self._get_obs()
    info = {}

    return obs, info

  def step(self, action):
    assert self.action_space.contains(action)

    prev_value = self._portfolio_value()

    if action == 1:
      if self.cash >= self.price:
        self.cash -= self.price
        self.inventory += 1

    elif action == 2:
      if self.inventory > 0:
        self.cash += self.price
        self.inventory -= 1

    self.price += np.random.normal(0, 0.5)
    self.price = max(1.0, self.price)

    current_value = self._portfolio_value()
    delta_pnl = current_value - self.prev_portfolio_value
    self.prev_portfolio_value = current_value

    self.timestamp += 1

    inventory_penalty = self.k_inventory * abs(self.inventory)
    risk_penalty = self.k_risk * (delta_pnl ** 2)

    reward = delta_pnl - inventory_penalty - risk_penalty

    terminated = False
    truncated = self.timestamp >= self.max_steps

    obs = self._get_obs()
    info = {
        "price": self.price,
        "inventory": self.inventory,
        "cash": self.cash
    }

    return obs, reward, terminated, truncated, info

  def _portfolio_value(self):
    return self.cash + self.inventory * self.price

  def _get_obs(self):
    price_norm = self.price / self.initial_price
    inventory_norm = self.inventory / 10.0
    cash_norm = self.cash / self.initial_cash

    return np.array(
        [price_norm, inventory_norm, cash_norm],
        dtype = np.float32
    )

env = TradingEnv(max_steps = 10)

obs, info = env.reset()
done = False

total_reward = 0.0

while not done:
  action = env.action_space.sample()
  obs, reward, terminated, truncated, info = env.step(action)
  total_reward += reward
  done = terminated or truncated

print("Episode finished")
print("Total reward:", total_reward)
print("Final info:", info)